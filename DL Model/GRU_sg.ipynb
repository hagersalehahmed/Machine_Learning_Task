{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7M2s6OoIexl",
        "outputId": "ee52c575-d596-41d6-8c5a-71f8dd6632d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 3.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XjZSolvm8K25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13cc43db-c770-4337-fd19-e4180c5e97ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "le = LabelEncoder() \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.utils import np_utils\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import gensim\n",
        "import re\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras import backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Print result"
      ],
      "metadata": {
        "id": "jApTLDrPAHxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vjE_mCVNvMRL"
      },
      "outputs": [],
      "source": [
        "def printResult(y_real, y_pred):\n",
        "    acc = accuracy_score(y_real, y_pred)\n",
        "    print(\"Accuracy: {:.2f}\".format(acc*100),end='\\n\\n')\n",
        "    print(classification_report(y_real,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlzBnQ_z8PAU",
        "outputId": "ae3d66f6-f12c-4b25-d34e-c5eeccb49934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading CBOW  using gensim"
      ],
      "metadata": {
        "id": "gjUnJEqUAZhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tRgbHx4W8K3A"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec.load('/content/drive/MyDrive/full_uni_sg_300_twitter.mdl')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading training and testing dataset"
      ],
      "metadata": {
        "id": "AAoDFsZcAsfH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rqNfvg4O8K3B"
      },
      "outputs": [],
      "source": [
        "#read train dataset\n",
        "train= pd.read_csv('/content/drive/MyDrive/ML task/Deep/train1.csv',encoding='utf-8')\n",
        "train=train.dropna()\n",
        "y_train = train.dialect                   \n",
        "X_train= train.drop(['dialect','id'],axis = 1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FlfPCQcq8K3E",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#reading testing data\n",
        "test= pd.read_csv('/content/drive/MyDrive/ML task/Deep/unseen1.csv',encoding='utf-8')\n",
        "test=test.dropna()\n",
        "y_test = test.dialect                           \n",
        "X_test= test.drop(['id','dialect'],axis = 1 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoder "
      ],
      "metadata": {
        "id": "QFPd2kZoA-di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tusq7R1v8K3G"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train= encoder.fit_transform(y_train)\n",
        "y_train_best=np_utils.to_categorical(y_train)\n",
        "encoder1 = LabelEncoder()\n",
        "y_test = encoder1.fit_transform(y_test)\n",
        "y_test_best=np_utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building word embedding"
      ],
      "metadata": {
        "id": "1egftzR4BN9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jZ2ZRUO8K3I",
        "outputId": "9fcedade-098e-4082-df0f-5cdd6c872561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens generated:  50714\n",
            "Shape of padded train tensor:  (12361, 140)\n",
            "Shape of padded test tensor:  (1375, 140)\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 140  \n",
        "BATCH_SIZE = 5000\n",
        "MAX_NUM_WORDS = 200000\n",
        "EMBEDDING_DIM = 300\n",
        "epoch=100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(X_train['text'])\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train['text'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "padded_train = pad_sequences(sequences=train_sequences, maxlen=MAX_LEN)\n",
        "print('Total unique tokens generated: ',len(word_index))\n",
        "print('Shape of padded train tensor: ', padded_train.shape)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test['text'])\n",
        "padded_test = pad_sequences(sequences=test_sequences, maxlen=MAX_LEN)\n",
        "\n",
        "print('Shape of padded test tensor: ', padded_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-LQ7S_508K3J"
      },
      "outputs": [],
      "source": [
        "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
        "word_embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))\n",
        "\n",
        "for word, index in word_index.items():\n",
        "    if index > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    if word not in model.wv:\n",
        "        embedding_vector = None\n",
        "    else:\n",
        "        embedding_vector = model.wv[word]\n",
        "    if embedding_vector is not None:\n",
        "        word_embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Pm7EWPE3IdqN"
      },
      "outputs": [],
      "source": [
        "output=len(train['dialect'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buliding deep learning using keras tuner"
      ],
      "metadata": {
        "id": "vOpChY6RBk_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RcTGP13Y8K3L"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    num_units_min  =  50\n",
        "    num_units_max  =  1000\n",
        "    num_units_step =  50\n",
        "\n",
        "    dropout_min  =  .1\n",
        "    dropout_max  =  0.9\n",
        "    dropout_step =  0.1\n",
        "    \n",
        "    model = keras.Sequential()\n",
        " \n",
        "    model.add(layers.Embedding(num_words + 1, EMBEDDING_DIM, weights=[word_embedding_matrix], input_length=MAX_LEN))\n",
        "\n",
        "    \n",
        "    model.add(layers.GRU(units=hp.Int('unit1',  min_value=num_units_min,\n",
        "                                                 max_value=num_units_max,\n",
        "                                                 step=num_units_step), return_sequences =False,  activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(layers.Dense(output, activation='softmax'))\n",
        "    model.compile( optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[ 1e-4])),loss='categorical_crossentropy', metrics=['acc'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Go5T198Y9Ee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee444c1-8794-456e-f995-8e82678651bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_acc',\n",
        "    max_trials=1,\n",
        "    project_name='/content/drive/MyDrive/ML task/Deep/GRU_sg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3yFp2dj8K3M",
        "outputId": "66099bc3-011b-4cd6-88d6-e2a3e5d63bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 04m 26s]\n",
            "val_acc: 0.3225545585155487\n",
            "\n",
            "Best val_acc So Far: 0.3225545585155487\n",
            "Total elapsed time: 00h 04m 26s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_acc', patience=30, verbose=1)\n",
        "callback_list = [ early_stopping ]\n",
        "\n",
        "h=tuner.search(padded_train, y_train_best,\n",
        "             epochs=epoch,\n",
        "             batch_size=BATCH_SIZE, \n",
        "             callbacks=callback_list, validation_split=0.1)         \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BCFxZQbYzJg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3563fdac-0ebf-40b9-d3b3-4f4cf0987d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "model = tuner.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "07SEaPSvmKh_"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/ML task/Deep/GRU_sg.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tLJa080e8K3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48de1ad2-014f-4615-8b96-5ed344a54da8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.0001, 'unit1': 250}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Print training result"
      ],
      "metadata": {
        "id": "48wFRZu3Ci4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aiAddvO2uqbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa0c1da-4760-4925-b394-8ac1a5fa2c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result of GRU\n",
            "Accuracy: 50.09\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.28      0.33       709\n",
            "           1       0.40      0.35      0.37       710\n",
            "           2       0.59      0.28      0.37       436\n",
            "           3       0.70      0.93      0.80      1556\n",
            "           4       0.83      0.20      0.32       416\n",
            "           5       0.39      0.35      0.37       754\n",
            "           6       0.48      0.67      0.56      1137\n",
            "           7       0.68      0.48      0.56       746\n",
            "           8       0.39      0.75      0.51       983\n",
            "           9       0.79      0.18      0.29       311\n",
            "          10       0.37      0.15      0.21       517\n",
            "          11       0.46      0.74      0.57      1181\n",
            "          12       0.43      0.60      0.50       838\n",
            "          13       0.49      0.44      0.46       724\n",
            "          14       0.61      0.14      0.23       390\n",
            "          15       0.64      0.17      0.27       436\n",
            "          16       0.33      0.00      0.01       249\n",
            "          17       0.57      0.05      0.09       268\n",
            "\n",
            "    accuracy                           0.50     12361\n",
            "   macro avg       0.53      0.38      0.38     12361\n",
            "weighted avg       0.52      0.50      0.46     12361\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_train_pred=model.predict(padded_train)\n",
        "y_pred= np.argmax(y_train_pred, axis=1)\n",
        "print(\"Train Result of GRU\")\n",
        "printResult(y_train,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print testing result"
      ],
      "metadata": {
        "id": "MBGV0dq3Cof1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TIJkiMhQE7hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0ffe7c-a138-4a92-d413-1344a6d3c78c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Result of GRU\n",
            "Accuracy: 29.67\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.10      0.12        79\n",
            "           1       0.12      0.11      0.12        79\n",
            "           2       0.25      0.08      0.12        48\n",
            "           3       0.57      0.76      0.65       173\n",
            "           4       0.00      0.00      0.00        46\n",
            "           5       0.10      0.10      0.10        84\n",
            "           6       0.32      0.41      0.36       126\n",
            "           7       0.41      0.24      0.30        83\n",
            "           8       0.22      0.50      0.30       110\n",
            "           9       0.67      0.06      0.11        35\n",
            "          10       0.14      0.05      0.08        57\n",
            "          11       0.27      0.50      0.35       131\n",
            "          12       0.26      0.32      0.29        93\n",
            "          13       0.29      0.23      0.26        81\n",
            "          14       0.17      0.02      0.04        43\n",
            "          15       0.00      0.00      0.00        49\n",
            "          16       0.00      0.00      0.00        28\n",
            "          17       0.00      0.00      0.00        30\n",
            "\n",
            "    accuracy                           0.30      1375\n",
            "   macro avg       0.22      0.19      0.18      1375\n",
            "weighted avg       0.26      0.30      0.26      1375\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_test_pred=model.predict(padded_test)\n",
        "y_pred= np.argmax(y_test_pred, axis=1)\n",
        "print(\"Testing Result of GRU\")\n",
        "printResult(y_test,y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "GRU_sg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}